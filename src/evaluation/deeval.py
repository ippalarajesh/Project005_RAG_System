# evaluation/deeval.py
class DeepEval:
    @staticmethod
    def evaluate(response, ground_truth):
        # Compare the generated response with the ground truth
        return {"accuracy": 0.95}  # Example metric
